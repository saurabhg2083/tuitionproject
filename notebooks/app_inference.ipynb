{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import pandas as pd\n",
    "\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "loss_fn = BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "binary_path: c:\\Python311\\Lib\\site-packages\\bitsandbytes\\cuda_setup\\libbitsandbytes_cuda116.dll\n",
      "CUDA SETUP: Loading binary c:\\Python311\\Lib\\site-packages\\bitsandbytes\\cuda_setup\\libbitsandbytes_cuda116.dll...\n",
      "Prediction: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load saved model\n",
    "save_directory = \"./model_part1\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the model\n",
    "model = BertForSequenceClassification.from_pretrained(save_directory)\n",
    "model.to(device)\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(save_directory)\n",
    "\n",
    "# Inference function\n",
    "def run_inference(model, tokenizer, text, device):\n",
    "    \"\"\"\n",
    "    Runs inference using the pretrained model and tokenizer.\n",
    "    \n",
    "    Parameters:\n",
    "        model: The pretrained model\n",
    "        tokenizer: The tokenizer\n",
    "        text: The text to run inference on\n",
    "        device: The device type ('cpu' or 'cuda')\n",
    "    \n",
    "    Returns:\n",
    "        prediction: 0 or 1 (based on the logit)\n",
    "    \"\"\"\n",
    "    # Tokenize the text\n",
    "    input_data = tokenizer([text], padding='max_length', truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    \n",
    "    # Load tensor to the specified device\n",
    "    input_ids = input_data['input_ids'].to(device)\n",
    "    attention_mask = input_data['attention_mask'].to(device)\n",
    "    token_type_ids = input_data['token_type_ids'].to(device)\n",
    "    \n",
    "    # Put model in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Run inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "    \n",
    "    # Get logits\n",
    "    logits = outputs.logits.squeeze().item()\n",
    "    \n",
    "    # Convert logits to predictions\n",
    "    prediction = int(logits > 0)  # This line is modified\n",
    "\n",
    "    return prediction\n",
    "\n",
    "# Run inference\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "text = \"Student Age: 7 Student Grade: 3 Source: mocktest Passage Name: dorian gray Genre: fiction Language Complexity: Extremely Difficult Sentence Structure: Extremely Difficult Themes and Content: Extremely Difficult Overall Complexity: Extremely Difficult Question: In whose residence does this passage take place? Question Difficulty: Challenging Question Type: Factual recall: there is a sentence that basically tells them the answer directly Answer Option A: Dorian Gray’s Answer Option B: Alan Campbell’s Answer Option C: Lord Henry Wotton’s Answer Option D: No one’s, it is occurring in public. Answer Option E: It is not mentioned in the text. Correct Answer: A Answer By Student: A Hour of exam: 14 Attention Level: High \"\n",
    "\n",
    "prediction = run_inference(model, tokenizer, text, device)\n",
    "\n",
    "print(f\"Prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import pandas as pd\n",
    "import pickle \n",
    "from torch.nn import CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Index: 3\n",
      "Decoded Prediction: D\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load\n",
    "with open(\"./model_part2_v2/label_encoder.pkl\", \"rb\") as f:\n",
    "    encoder = pickle.load(f)\n",
    "    \n",
    "# Directory where model will be saved\n",
    "save_directory = \"./model_part2_v2\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the model\n",
    "model = BertForSequenceClassification.from_pretrained(save_directory)\n",
    "model.to(device)\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(save_directory)\n",
    "\n",
    "def run_multiclass_inference(model, tokenizer, encoder, text, device):\n",
    "    \"\"\"\n",
    "    Runs inference using a pretrained model and tokenizer for multi-class classification.\n",
    "    \n",
    "    Parameters:\n",
    "        model: The pretrained model\n",
    "        tokenizer: The tokenizer\n",
    "        text: The text to run inference on\n",
    "        device: The device type ('cpu' or 'cuda')\n",
    "    \n",
    "    Returns:\n",
    "        prediction: Label index with the highest logit value\n",
    "    \"\"\"\n",
    "    # Tokenize the text\n",
    "    input_data = tokenizer([text], padding='max_length', truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    \n",
    "    # Load tensor to the specified device\n",
    "    input_ids = input_data['input_ids'].to(device)\n",
    "    attention_mask = input_data['attention_mask'].to(device)\n",
    "    token_type_ids = input_data['token_type_ids'].to(device)\n",
    "    \n",
    "    # Put model in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Run inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "    \n",
    "    # Get logits\n",
    "    logits = outputs.logits\n",
    "    \n",
    "    # Get label index with the maximum logit\n",
    "    prediction = torch.argmax(logits, dim=1).cpu().item()\n",
    "\n",
    "    return prediction\n",
    "\n",
    "text = \"Student Age: 7 Student Grade: 3 Source: mocktest Passage Name: dorian gray Genre: fiction Language Complexity: Extremely Difficult Sentence Structure: Extremely Difficult Themes and Content: Extremely Difficult Overall Complexity: Extremely Difficult Question: In whose residence does this passage take place? Question Difficulty: Challenging Question Type: Factual recall: there is a sentence that basically tells them the answer directly Answer Option A: Dorian Gray’s Answer Option B: Alan Campbell’s Answer Option C: Lord Henry Wotton’s Answer Option D: No one’s, it is occurring in public. Answer Option E: It is not mentioned in the text. Correct Answer: A Answer By Student: A Hour of exam: 14 Attention Level: High \"\n",
    "text = \"Student Age: 7 Student Grade: 3 Source: mocktest Passage Name: dorian gray Genre: fiction Language Complexity: Extremely Difficult Sentence Structure: Extremely Difficult Themes and Content: Extremely Difficult Overall Complexity: Extremely Difficult Question: ‘There was a look of contempt in the steady searching gaze that he turned on Dorian.’ (lines 2-3) Which of the following best describes Alan’s initial assessment of Dorian? Question Difficulty: Difficult Question Type: Factual recall: there is a sentence that basically tells them the answer directly Answer Option A: He is not familiar with him and is thus curious. Answer Option B: He respects him but isn’t particularly interested. Answer Option C: He is wary of him and looking out for danger. Answer Option D: He detests him and wants to turn away from him. Answer Option E: He is scornful and evaluating. Correct Answer: E Answer By Student: D Hour of exam: 14 Attention Level: High \"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "prediction_index = run_multiclass_inference(model, tokenizer, encoder, text, device)\n",
    "\n",
    "decoded_prediction = encoder.inverse_transform([prediction_index])\n",
    "\n",
    "print(f\"Prediction Index: {prediction_index}\")\n",
    "print(f\"Decoded Prediction: {decoded_prediction[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
